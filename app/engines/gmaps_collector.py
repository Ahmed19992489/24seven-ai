import time
import re
import os
import platform
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

class GmapsEngine:
    def __init__(self):
        self.driver = self._setup_driver()

    def _setup_driver(self):
        """
        Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ØªØµÙØ­ Ù„ÙŠØ¹Ù…Ù„ Ø¨Ø°ÙƒØ§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ±ÙØ± (Render) ÙˆØ¹Ù„Ù‰ Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ø´Ø®ØµÙŠ
        Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… undetected_chromedriver Ù„ØªØ¬Ù†Ø¨ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø³ÙŠØ±ÙØ±
        """
        chrome_options = Options()
        
        # --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø³ÙŠØ±ÙØ± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ---
        chrome_options.add_argument("--headless=new") # ØªØ´ØºÙŠÙ„ Ø¨Ø¯ÙˆÙ† Ø´Ø§Ø´Ø©
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--window-size=1920,1080")
        chrome_options.add_argument("--disable-notifications")
        chrome_options.add_argument("--blink-settings=imagesEnabled=false") # ØªØ³Ø±ÙŠØ¹

        # --- ÙƒØ´Ù Ù…Ø³Ø§Ø± ÙƒØ±ÙˆÙ… Ø¹Ù„Ù‰ Render ---
        chrome_bin = os.environ.get("CHROME_BIN")
        if chrome_bin:
            print(f"ğŸ–¥ï¸ Render Environment Detected. Using Chrome at: {chrome_bin}")
            chrome_options.binary_location = chrome_bin
        else:
            print("ğŸ’» Local Environment Detected.")

        try:
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠØ©
            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=chrome_options)
            return driver
        except Exception as e:
            print(f"âš ï¸ ÙØ´Ù„ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØŒ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ÙŠØ¯ÙˆÙŠØ©... {e}")
            try:
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
                driver = webdriver.Chrome(options=chrome_options)
                return driver
            except Exception as final_e:
                print(f"âŒ Ø®Ø·Ø£ Ù‚Ø§ØªÙ„: Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…ØªØµÙØ­! {final_e}")
                raise final_e

    def scrape(self, keyword: str, location: str, max_leads: int = 10):
        results = []
        try:
            query = f"{keyword} in {location}"
            print(f"ğŸš€ [Gmaps] Searching: {query} (Target: {max_leads})")
            
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø±Ø§Ø¨Ø· Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
            self.driver.get(f"https://www.google.com/maps/search/{query}")
            
            wait = WebDriverWait(self.driver, 20)
            try:
                # Ø§Ù†ØªØ¸Ø§Ø± Ø¸Ù‡ÙˆØ± Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (ØªØºÙŠØ± Ø§Ù„Ø³ÙŠÙ„ÙƒØªÙˆØ± Ø­Ø³Ø¨ ØªØ­Ø¯ÙŠØ«Ø§Øª Ø¬ÙˆØ¬Ù„)
                wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div[role='feed']")))
            except:
                print("âš ï¸ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù„Ù… ØªØ¸Ù‡Ø±ØŒ Ù†Ø­Ø§ÙˆÙ„ Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©...")

            # --- Ù…Ù†Ø·Ù‚ Ø§Ù„ØªÙ…Ø±ÙŠØ± (Scrolling Logic) ---
            print("ğŸ“œ Scrolling to load leads...")
            
            # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù†ØµØ± Ø§Ù„Ù‚Ø§Ø¨Ù„ Ù„Ù„Ø³ÙƒØ±ÙˆÙ„ (ØºØ§Ù„Ø¨Ø§Ù‹ Ù‡Ùˆ Ø§Ù„Ù€ Feed)
            try:
                scrollable_div = self.driver.find_element(By.CSS_SELECTOR, "div[role='feed']")
                
                last_count = 0
                retries = 0
                
                # Ø­Ù„Ù‚Ø© Ø§Ù„Ø³ÙƒØ±ÙˆÙ„
                while len(self.driver.find_elements(By.CSS_SELECTOR, "a[href*='/maps/place/']")) < max_leads:
                    self.driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', scrollable_div)
                    time.sleep(2) 
                    
                    current_count = len(self.driver.find_elements(By.CSS_SELECTOR, "a[href*='/maps/place/']"))
                    
                    if current_count == last_count:
                        retries += 1
                        if retries >= 3: 
                            print("ğŸ Reached end of available leads.")
                            break
                    else:
                        retries = 0
                        
                    last_count = current_count
                    print(f"â³ Leads Loaded: {current_count}...")
                    
                    if current_count >= max_leads:
                        break
            except Exception as e:
                print(f"âš ï¸ Scrolling issue: {e}")

            # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
            company_links = self.driver.find_elements(By.CSS_SELECTOR, "a[href*='/maps/place/']")
            print(f"ğŸ” Total leads found: {len(company_links)}")

            # --- Ø¨Ø¯Ø§ÙŠØ© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
            for link in company_links[:max_leads]:
                try:
                    # Ø§Ù„Ù†Ù‚Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù†ØµØ± Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙØ§ØµÙŠÙ„
                    self.driver.execute_script("arguments[0].click();", link)
                    time.sleep(2) # Ø§Ù†ØªØ¸Ø§Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙØ§ØµÙŠÙ„
                    
                    # Ø³Ø­Ø¨ Ø§Ù„Ø§Ø³Ù…
                    name = link.get_attribute("aria-label") or "Unknown"
                    
                    # Ø³Ø­Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØµÙØ­Ø© Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø±Ù‚Ø§Ù…
                    page_html = self.driver.page_source
                    
                    # ---------------------------------------------------------
                    # ğŸ”¥ Ù…Ù†Ø·Ù‚ Ø³Ø­Ø¨ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø© (Regex)
                    # ---------------------------------------------------------
                    phone = "ØºÙŠØ± Ù…ØªÙˆÙØ±"
                    
                    # 1. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… (Ù…ÙˆØ¨Ø§ÙŠÙ„ ÙˆØ£Ø±Ø¶ÙŠ Ù…ØµØ±ÙŠ)
                    # Ù‡Ø°Ø§ Ø§Ù„ØªØ¹Ø¨ÙŠØ± Ø§Ù„Ù†Ù…Ø·ÙŠ ÙŠØ¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„ØªÙŠ ØªØ¨Ø¯Ø£ Ø¨Ù€ +20 Ø£Ùˆ 0
                    all_numbers = re.findall(r'(?:\+20|0)(?:1[0125]|2)\d{8}', page_html)
                    
                    # 2. Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±
                    unique_numbers = list(set(all_numbers))
                    
                    if unique_numbers:
                        # 3. ØªØ±ØªÙŠØ¨ Ø°ÙƒÙŠ: Ø§Ù„Ù…ÙˆØ¨Ø§ÙŠÙ„ Ø£ÙˆÙ„Ø§Ù‹ØŒ Ø«Ù… Ø§Ù„Ø£Ø±Ø¶ÙŠ
                        unique_numbers.sort(key=lambda x: 0 if x.startswith(('01', '+201')) else 1)
                        
                        # 4. Ø¯Ù…Ø¬ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø¨ÙØ§ØµÙ„
                        phone = " | ".join(unique_numbers)
                    # ---------------------------------------------------------

                    # Ø³Ø­Ø¨ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ (Ù…Ø­Ø§ÙˆÙ„Ø©)
                    website = "ØºÙŠØ± Ù…ØªÙˆÙØ±"
                    try:
                        web_elem = self.driver.find_element(By.CSS_SELECTOR, "a[data-item-id='authority']")
                        website = web_elem.get_attribute("href")
                    except:
                        pass

                    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù†ØªÙŠØ¬Ø©
                    results.append({
                        "company_name": name,
                        "industry": keyword,
                        "location": location,
                        "phone": phone, 
                        "website": website,
                        "map_link": link.get_attribute("href")
                    })
                    print(f"âœ… Data Captured: {name} | ğŸ“ {phone}")

                except Exception as inner_e:
                    print(f"âš ï¸ Error parsing item: {inner_e}")
                    continue
        
        except Exception as e:
            print(f"âŒ Critical Gmaps Error: {e}")
            
        finally:
            # Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù…ØªØµÙØ­ ÙˆØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            try:
                self.driver.quit()
            except:
                pass
            
        return results

# Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±ÙŠØ¹ Ø¹Ù†Ø¯ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
if __name__ == "__main__":
    engine = GmapsEngine()
    data = engine.scrape("Gym", "Cairo", 3)
    print("Final Data:", data)