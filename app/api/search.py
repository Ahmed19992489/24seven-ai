from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks
from sqlalchemy.orm import Session
from app.database import get_db
from app import models, schemas
from app.api.auth import get_current_user
from pydantic import BaseModel
import time

# Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
# ØªØ£ÙƒØ¯ Ø£Ù† Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù„ÙØ§Øª Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù…Ø¬Ù„Ø¯ app/engines/
from app.engines.gmaps_collector import GmapsEngine
from app.engines.data_enricher import DataEnricher
from app.engines.verifier_pro import EmailVerifier

router = APIRouter()

# --- 1. ØªØ¹Ø±ÙŠÙ Ø´ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© (Schema) ---
# Ù‡Ø°Ø§ Ø§Ù„ÙƒÙ„Ø§Ø³ Ù‡Ùˆ "Ø§Ù„Ù…ØªØ±Ø¬Ù…" Ø§Ù„Ø°ÙŠ Ø³ÙŠÙÙ‡Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø§Ø¯Ù…Ø© Ù…Ù† Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯
class SearchRequest(BaseModel):
    keyword: str
    location: str
    target_limit: int = 5

# --- 2. Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø´Ø§Ù…Ù„Ø© (ØªÙ†ÙØ° ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©) ---
def run_full_scraping_task(keyword: str, location: str, user_id: int, db: Session, limit: int):
    print(f"ğŸš€ [Task Started] Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†: {keyword} ÙÙŠ {location} (Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰: {limit})")
    
    gmaps = GmapsEngine()
    enricher = DataEnricher()
    verifier = EmailVerifier()
    
    try:
        # Ø£) Ø³Ø­Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ù† Ø®Ø±Ø§Ø¦Ø· Ø¬ÙˆØ¬Ù„
        # Ù…Ù„Ø§Ø­Ø¸Ø©: ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ø¯Ø§Ù„Ø© gmaps.scrape ØªÙ‚Ø¨Ù„ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª ÙˆØªØ¹Ù…Ù„ Ø¨ÙˆØ¶Ø¹ Headless Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ±ÙØ±
        raw_results = gmaps.scrape(keyword, location, max_leads=limit)
        
        if not raw_results:
            print(f"âš ï¸ [Warning] Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ø®Ø±Ø§Ø¦Ø· Ø¬ÙˆØ¬Ù„ Ù„Ù€: {keyword}")
            return

        print(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(raw_results)} Ø´Ø±ÙƒØ©. Ø¨Ø¯Ø¡ Ø§Ù„Ø¥Ø«Ø±Ø§Ø¡ ÙˆØ§Ù„ØªØ­Ù‚Ù‚...")

        # Ø¨) Ø¨Ø¯Ø¡ Ø¬Ù„Ø³Ø© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ù…ÙŠÙ‚ (Ø§Ù„Ø¥Ø«Ø±Ø§Ø¡)
        enricher.start_session()
        
        leads_saved = 0
        for item in raw_results:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø´Ø±ÙƒØ© Ù…Ø³Ø¨Ù‚Ø§Ù‹ Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø± (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            # existing_lead = db.query(models.Lead).filter(models.Lead.company_name == item['company_name'], models.Lead.user_id == user_id).first()
            # if existing_lead: continue

            # Ø¬) Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ø¹Ù† Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„ ÙˆØµØ§Ù†Ø¹ Ø§Ù„Ù‚Ø±Ø§Ø±
            extra_data = enricher.find_emails_and_people(item['company_name'], item['website'])
            
            # Ø¯) Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„ ØªÙ‚Ù†ÙŠØ§Ù‹
            email_status, confidence = verifier.verify(extra_data['email'])
            
            # Ù‡Ù€) Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            new_lead = models.Lead(
                user_id=user_id,
                company_name=item['company_name'],
                industry=keyword,
                location=item['location'] or location, # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù…Ø¯Ø®Ù„ ÙƒØ§Ø­ØªÙŠØ§Ø·ÙŠ
                phone=item['phone'],
                website=item['website'],
                email=extra_data['email'],
                email_status=email_status,
                confidence_score=confidence,
                decision_maker_name=extra_data['decision_maker_name'],
                decision_maker_role=extra_data['decision_maker_role'],
                linkedin_url=extra_data['linkedin_url']
            )
            db.add(new_lead)
            db.commit()
            leads_saved += 1
            print(f"ğŸ’¾ [Saved] {item['company_name']} ({email_status})")

        enricher.stop_session()
        
        # Ùˆ) ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ®
        history = models.SearchHistory(
            user_id=user_id,
            keyword=keyword,
            location=location,
            results_count=leads_saved
        )
        db.add(history)
        db.commit()
        print(f"ğŸ [Task Finished] ØªÙ…Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­. ØªÙ… Ø­ÙØ¸ {leads_saved} Ø¹Ù…ÙŠÙ„.")

    except Exception as e:
        print(f"âŒ [Critical Error] Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ: {e}")
        db.rollback()
    finally:
        try:
            enricher.stop_session()
        except:
            pass

# --- 3. Ù†Ù‚Ø·Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ø¨Ø­Ø« (Endpoint) ---
@router.post("/start-search/")
def start_search(
    request: SearchRequest,  # Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙƒÙ€ JSON Body
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db),
    current_user: models.User = Depends(get_current_user)
):
    # Ø£) Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±ØµÙŠØ¯
    if current_user.credits < request.target_limit:
        raise HTTPException(status_code=400, detail="Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø±ØµÙŠØ¯Ùƒ Ø§Ù„Ø­Ø§Ù„ÙŠ Ù„Ø§ ÙŠÙƒÙÙŠ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©.")

    # Ø¨) Ø®ØµÙ… Ø§Ù„Ø±ØµÙŠØ¯ ÙÙˆØ±Ø§Ù‹
    current_user.credits -= request.target_limit
    db.commit()
    
    # Ø¬) Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù‡Ù…Ø© Ù„Ù„Ø®Ù„ÙÙŠØ© (Background Task)
    background_tasks.add_task(
        run_full_scraping_task, 
        request.keyword, 
        request.location, 
        current_user.id, 
        db, 
        request.target_limit
    )
    
    return {
        "status": "success", 
        "message": f"ØªÙ… Ø¨Ø¯Ø¡ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† '{request.keyword}'. ØªÙ… Ø®ØµÙ… {request.target_limit} Ù†Ù‚Ø·Ø©. Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø³ØªØ¸Ù‡Ø± ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¹Ù†Ø¯ Ø§ÙƒØªÙ…Ø§Ù„Ù‡Ø§."
    }

# --- 4. Ø¬Ù„Ø¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Ù„Ù„Ø¹Ø±Ø¶ ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„) ---
@router.get("/my-leads/")
def get_my_leads(db: Session = Depends(get_db), current_user: models.User = Depends(get_current_user)):
    leads = db.query(models.Lead).filter(models.Lead.user_id == current_user.id).order_by(models.Lead.id.desc()).limit(100).all()
    return {"data": leads}

# --- 5. Ø¬Ù„Ø¨ Ø³Ø¬Ù„ Ø§Ù„Ø¨Ø­Ø« (Ù„Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©) ---
@router.get("/history")
def get_history(db: Session = Depends(get_db), current_user: models.User = Depends(get_current_user)):
    return db.query(models.SearchHistory).filter(models.SearchHistory.user_id == current_user.id).order_by(models.SearchHistory.id.desc()).all()